---
---

@string{aps = {American Physical Society,}}

@article{chen2023theoremqa,
  abbr={Preprint},
  title={TheoremQA: A Theorem-driven Question Answering dataset},
  author={Chen, Wenhu and Yin, Ming and Ku, Max and Wan, Elaine and Ma, Xueguang and Xu, Jianyu and Xia, Tony and Wang, Xinyi and Lu, Pan},
  journal={arXiv preprint arXiv:2305.12524},
  arxiv={2305.12524},
  year={2023},
  selected={true}
}


@article{no_regret_b_r,
  abbr={UAI},
  title={No-Regret Linear Bandits beyond Realizability},
  author={Liu, Chong and Yin, Ming and Wang, Yu-Xiang},
  journal={Uncertainty in Artificial Intelligence,},
  arxiv={2302.13252},
  year={2023},
  selected={false}
}


@article{DMY_low_switching,
  abbr={Preprint},
  title={Logarithmic Switching Cost in Reinforcement Learning beyond Linear MDPs},
  author={Qiao, Dan and Yin, Ming and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2302.12456},
  arxiv={2302.12456},
  year={2023},
  selected={false}
}


@article{songtao2023,
  abbr={ICML},
  title={Non-stationary Reinforcement Learning under General Function Approximation}, 
  author={Feng, Songtao and Yin, Ming and Huang, Ruiquan and Wang, Yu-Xiang and Yang, Jing and Liang, Yingbin},
  journal={International Conference on Machine Learning,},
  year={2023},
  arxiv={2306.00861},
  selected={false}
}


@article{lioffline2022,
  abbr={ICML},
  title={Offline Reinforcement Learning with Closed-Form Policy Improvement Operators}, 
  author={Li, Jiachen and Zhang, Edwin and Yin, Ming and Bai, Qinxun and Wang, Yu-Xiang and Wang, William Yang},
  journal={International Conference on Machine Learning (Short version at NeurIPS-22 Offline RL Workshop),},
  year={2023},
  arxiv={2211.15956},
  selected={false}
}


@article{yin2022offline,
  abbr={ICLR},
  title={Offline Reinforcement Learning with Differentiable Function Approximation is Provably Efficient},
  author={Yin, Ming and Wang, Mengdi and Wang, Yu-Xiang},
  journal={International Conference on Learning Representations,},
  arxiv={2210.00750},
  year={2023},
  html={https://openreview.net/pdf?id=6jfbOWzWTcE},
  selected={true}
}

@article{quantization,
  abbr={ICML WS},
  title={Why Quantization Improves Generalization: NTK of Binary Weight Neural Networks},
  author={Zhang, Kaiqi and Yin, Ming and Wang, Yu-Xiang},
  journal={ICML workshop in Neural Compression,},
  arxiv={2206.05916},
  year={2023},
  selected={false}
}


@article{yin2021near-optimal,
  abbr={ICLR},
  title={Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism}, 
  author={Yin, Ming and Duan, Yaqi and Wang, Mengdi and Wang, Yu-Xiang},
  journal={International Conference on Learning Representations,},
  year={2022},
  arxiv={2203.05804},
  html={https://openreview.net/pdf?id=KLaDXLAzzFT},
  selected={true}
}

@article{loglog,
  abbr={ICML},
  award={Spotlight},
  title={Sample-Efficient Reinforcement Learning with loglog(T) Switching Cost}, 
  author={Qiao, Dan and Yin, Ming and Min, Ming and Wang, Yu-Xiang},
  journal={International Conference on Machine Learning,},
  year={2022},
  html={https://proceedings.mlr.press/v162/qiao22a/qiao22a.pdf},
  arxiv={2202.06385},
  selected={false}
}


@article{sunil2022,
  abbr={NeurIPS WS},
  title={Offline Policy Evaluation for Reinforcement Learning with Adaptively Collected Data}, 
  author={Madhow, Sunil and Qiao, Dan and Ming, Yin and Wang, Yu-Xiang},
  journal={NeurIPS workshop in Offline RL,},
  year={2022},
  html={https://openreview.net/pdf?id=09uAvDy-fL},
  selected={false}
}



@article{aaai23,
  abbr={AAAI},
  title={On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation}, 
  author={Nguyen-Tan, Thanh and Yin, Ming and Gupta, Sunil and Venkates, Svetha and Arora, Raman},
  journal={Association for the Advancement of Artificial Intelligence,},
  year={2023},
  arxiv = {2211.13208},
  selected={false}
}


@article{offlineSSP,
  abbr={UAI},
  award={Spotlight},
  title={Offline Stochastic Shortest Path: Learning, Evaluation and Towards Optimality}, 
  author={Yin*, Ming and Chen*, Wenjing and Wang, Mengdi and Wang, Yu-Xiang},
  journal={Uncertainty in Artificial Intelligence,},
  year={2022},
  html={https://openreview.net/pdf?id=HtW4EdIsqlq},
  arxiv={2206.04921},
  selected={true}
}

@article{yin2021towards,
  abbr={NeurIPS},
  title={Towards Instance-optimal Offline Reinforcement Learning with Pessimism}, 
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={Advances in Neural Information Processing Systems,},
  year={2021},
  arxiv={2110.08695},
  html={https://papers.nips.cc/paper/2021/hash/212ab20dbdf4191cbcdcf015511783f4-Abstract.html},
  selected={true}
}


@article{yin2021characterizing,
  abbr={NeurIPS},
  title={Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings}, 
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={Advances in Neural Information Processing Systems (Short version at ICML RL Theory Workshop),},
  year={2021},
  arxiv={2105.06029},
  html={https://papers.nips.cc/paper/2021/hash/6b3c49bdba5be0d322334e30c459f8bd-Abstract.html},
  selected={true}
}



@article{yin2021near,
  abbr={NeurIPS},
  title={Near-Optimal Offline Reinforcement Learning via Double Variance Reduction},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={Advances in Neural Information Processing Systems (Short version at ICML RL Theory Workshop),},
  arxiv={2102.01748},
  html={https://papers.nips.cc/paper/2021/hash/3f24bb08a5741e4197af64e1f93a5029-Abstract.html},
  year={2021},
  selected={true}
}


@article{yin2020near,
  abbr={AISTATS},
  award={Oral Presentation},
  html={http://proceedings.mlr.press/v130/yin21a.html},
  arxiv={2007.03760},
  title={Near-optimal Provable Uniform Convergence in Offline Policy Evaluation for Reinforcement Learning},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={International Conference on Artificial Intelligence and Statistics (Short version at Neurips 2020 Offline RL Workshop),},
  year={2021},
  selected={true}
}


@article{yin2020asymptotically,
  abbr={AISTATS},
  title={Asymptotically Efficient Off-policy Evaluation for Tabular Reinforcement Learning},
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={International Conference on Artificial Intelligence and Statistics,},
  arxiv={2001.10742},
  volume={17},
  pages={549--560},
  html={http://proceedings.mlr.press/v108/yin20b.html},
  year={2020},
  selected={true}
}
