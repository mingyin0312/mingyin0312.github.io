@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXivreprint arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}

@inproceedings{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@inproceedings{jiang2016doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016},
  organization={PMLR}
}

@article{yin2021optimal,
  title={Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings},
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2105.06029},
  year={2021}
}

@inproceedings{yin2021near,
  title={Near-optimal provable uniform convergence in offline policy evaluation for reinforcement learning},
  author={Yin, Ming and Bai, Yu, and Wang, Yu-Xiang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2021},
  organization={PMLR}
}

@article{yin2021nearoptimal,
  title={Near-Optimal Offline Reinforcement Learning via Double Variance Reduction},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2102.01748},
  year={2021}
}
