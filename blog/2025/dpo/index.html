<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>DPO From Scratch | Ming  Yin</title>
    <meta name="author" content="Ming  Yin">
    <meta name="description" content="This post explains my pytorch implementation of Direct Preference Optimization Algorithm.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/Princeton_seal.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://mingyin0312.github.io/blog/2025/dpo/">
    
    <!-- Dark Mode -->
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "DPO From Scratch",
      "description": "This post explains my pytorch implementation of Direct Preference Optimization Algorithm.",
      "published": "August 18, 2025",
      "authors": [
        {
          "author": "Ming Yin",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Princeton ECE",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">MingÂ </span>Yin</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/research/">Research</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching/Talks</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Miscellaneous</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>DPO From Scratch</h1>
        <p>This post explains my pytorch implementation of Direct Preference Optimization Algorithm.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <p><strong>Direct Preference Optimization</strong> <d-cite key="rafailov2023direct"></d-cite> is an LLM alignment method that directly trains a language model to prefer human-preferred outputs over rejected ones by minimizing a contrastive loss between the two. Unlike the standard RLHF, it does not require an explicit reward model to fit/train.</p>

<p>To uncover the implementation details in the minimal way, I implemented DPO from scratch with PyTorch in ðŸ‘‰ <a href="https://github.com/mingyin0312/RLFromScratch/blob/main/dpo_train_from_scratch.py" rel="external nofollow noopener" target="_blank">RLFromScratch</a>. Letâ€™s now understand it step by step.</p>

<hr>

<h3 id="quick-recap-of-dpo-algorithm">Quick Recap of DPO Algorithm</h3>

<p>Given a reward function, the RL Fine-tuning phase optimizes LLM via</p>

\[\max _{\pi_\theta} \mathbb{E}_{x \sim \mathcal{D}, y \sim \pi_\theta(y \mid x)}\left[r_\phi(x, y)\right]-\beta \mathbb{D}_{\mathrm{KL}}\left[\pi_\theta(y \mid x) \| \pi_{\mathrm{ref}}(y \mid x)\right].\]

<p>Given the partition function $Z(x)=\sum_y \pi_{\mathrm{ref}}(y \mid x) \exp \left(\frac{1}{\beta} r(x, y)\right)$, the closed-form solution takes</p>

\[\pi_r(y \mid x)=\frac{1}{Z(x)} \pi_{\mathrm{ref}}(y \mid x) \exp \left(\frac{1}{\beta} r(x, y)\right)\]

<p>This further gives</p>

\[r(x, y)=\beta \log \frac{\pi_r(y \mid x)}{\pi_{\mathrm{ref}}(y \mid x)}+\beta \log Z(x) .\]

<p>Under the Bradley-Terry model, the preference model follows:</p>

\[p^*\left(y_1 \succ y_2 \mid x\right)=\frac{1}{1+\exp \left(\beta \log \frac{\pi^*\left(y_2 \mid x\right)}{\pi_{\mathrm{ref}}\left(y_2 \mid x\right)}-\beta \log \frac{\pi^*\left(y_1 \mid x\right)}{\pi_{\mathrm{ref}}\left(y_1 \mid x\right)}\right)}\]

<p>So the negative likelihood naturally provides the following DPO loss:</p>

\[\mathcal{L}_{\mathrm{DPO}}(\pi_\theta,\pi_{\mathrm{ref}})=-\mathbb{E}_{\left(x, y_w, y_l\right) \sim \mathcal{D}}\left[\log \sigma\left(\beta \log \frac{\pi_\theta\left(y_w \mid x\right)}{\pi_{\mathrm{ref}}\left(y_w \mid x\right)}-\beta \log \frac{\pi_\theta\left(y_l \mid x\right)}{\pi_{\mathrm{ref}}\left(y_l \mid x\right)}\right)\right].\]

<p>Our code implmented above loss for training.</p>

<hr>

<h3 id="code-explanation">Code Explanation</h3>

<p><strong>- Format Input</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">input_ids</span><span class="p">,</span> <span class="n">labels_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">chosen_resp</span><span class="p">,</span> <span class="n">rejected_resp</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="c1"># Token IDs for prompt &amp; responses
</span>        <span class="n">p_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">c_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">chosen_resp</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>
        <span class="n">r_ids</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">rejected_resp</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>
        <span class="c1"># Build input IDs
</span>        <span class="n">input_ids</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">p_ids</span> <span class="o">+</span> <span class="n">c_ids</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">),</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">p_ids</span> <span class="o">+</span> <span class="n">r_ids</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c1"># Build labels: mask prompt with -100, keep response tokens
</span>        <span class="n">labels_list</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">p_ids</span><span class="p">)</span> <span class="o">+</span> <span class="n">c_ids</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">),</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="n">p_ids</span><span class="p">)</span> <span class="o">+</span> <span class="n">r_ids</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">input_ids</span> <span class="o">=</span> <span class="nf">pad_sequence</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_ids</span> <span class="o">!=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
    <span class="n">labels_tensor</span> <span class="o">=</span> <span class="nf">pad_sequence</span><span class="p">(</span><span class="n">labels_list</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=-</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">input_ids</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">attention_mask</span><span class="p">.</span><span class="n">shape</span> <span class="ow">and</span> <span class="n">attention_mask</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">labels_tensor</span><span class="p">.</span><span class="n">shape</span>

    <span class="k">return</span> <span class="n">input_ids</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">local_rank</span><span class="p">),</span> <span class="n">attention_mask</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">local_rank</span><span class="p">),</span> <span class="n">labels_tensor</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
</code></pre></div></div>

<p>This function appends chosen and rejected responses sequentially into a batch, pad_sequence ued to align the length of the batch. attention_mask is used as an input for attention score computation, and labels are used for loss computation.</p>

<p><strong>- Forward current model</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="n">logits</span>  <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span> <span class="c1">#.float()  # [B*2, T, V]
</span></code></pre></div></div>

<p>Here logits denote the output logits of the LLM.</p>

<p><strong>- Forward ref model (no grad)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="sh">'</span><span class="s">cuda</span><span class="sh">'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">):</span>
        <span class="n">ref_outputs</span> <span class="o">=</span> <span class="nf">ref_model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
    <span class="n">ref_logits</span>  <span class="o">=</span> <span class="n">ref_outputs</span><span class="p">.</span><span class="n">logits</span> 
</code></pre></div></div>

<p>Here ref_logits denote the output logits of the reference LLM.</p>

<p><strong>- Shift logits and labels</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[...,:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:].</span><span class="nf">contiguous</span><span class="p">()</span> <span class="c1"># [2B, T-1, V]
</span><span class="n">ref_logits</span> <span class="o">=</span> <span class="n">ref_logits</span><span class="p">[...,:</span><span class="o">-</span><span class="mi">1</span><span class="p">,:].</span><span class="nf">contiguous</span><span class="p">()</span> <span class="c1"># [2B, T-1, V]
</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[...,</span><span class="mi">1</span><span class="p">:].</span><span class="nf">contiguous</span><span class="p">()</span> <span class="c1"># [2B, T-1]
</span></code></pre></div></div>

<p>This shift is required for cross-entropy loss computation.</p>

<p><strong>- Compute per-token NLLs</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">V</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">loss_t</span>  <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span>
    <span class="n">logits</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">V</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span>
<span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="n">logits</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ref_loss</span><span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">cross_entropy</span><span class="p">(</span>
    <span class="n">ref_logits</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">V</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span>
<span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="n">ref_logits</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Here <code class="language-plaintext highlighter-rouge">loss_t</code> represents elementwise $-\log \pi_\theta(o_t \mid o_{&lt;t},x)$  and <code class="language-plaintext highlighter-rouge">ref_loss</code> elementwise $-\log \pi_{\mathrm{ref}}(o_t \mid o_{&lt;t},x)$.</p>

<p><strong>- Sum to get sequence NLL</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nll_seq</span>     <span class="o">=</span> <span class="n">loss_t</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ref_nll_seq</span> <span class="o">=</span> <span class="n">ref_loss</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Note by chain rule $\log\pi(y \mid x) = \log \prod_t \pi(o_t \mid o_{&lt;t},x)=\sum\log \pi(o_t \mid o_{&lt;t}, x)$, this convert elementwise <code class="language-plaintext highlighter-rouge">loss_t</code> and <code class="language-plaintext highlighter-rouge">ref_loss</code> to $-\log \pi_\theta\left(y_w \mid x\right)$ and $-\log \pi_{\mathrm{ref}}\left(y_w \mid x\right)$.</p>

<p><strong>- Inner</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">diff_theta</span> <span class="o">=</span> <span class="n">nll_r</span> <span class="o">-</span> <span class="n">nll_c</span>
<span class="n">diff_ref</span>   <span class="o">=</span> <span class="n">ref_r</span> <span class="o">-</span> <span class="n">ref_c</span>
<span class="n">inner</span>      <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">diff_theta</span> <span class="o">-</span> <span class="n">diff_ref</span><span class="p">)</span>
</code></pre></div></div>
<p>This computes $\beta \log \frac{\pi_\theta\left(y_w \mid x\right)}{\pi_{\mathrm{ref}}\left(y_w \mid x\right)}-\beta \log \frac{\pi_\theta\left(y_l \mid x\right)}{\pi_{\mathrm{ref}}\left(y_l \mid x\right)}$</p>

<p><strong>- DPO loss</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dpo_loss</span>   <span class="o">=</span> <span class="o">-</span><span class="n">F</span><span class="p">.</span><span class="nf">logsigmoid</span><span class="p">(</span><span class="n">inner</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span> 
</code></pre></div></div>

<p>This computes \(\mathcal{L}_{\mathrm{DPO}}(\pi_\theta,\pi_{\mathrm{ref}})\) . Note <code class="language-plaintext highlighter-rouge">F.logsigmoid</code> is crucial for numerical stability.</p>

<h2 id="miscellaneous">Miscellaneous</h2>

<p>Also see this on twitter:</p>
<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet" data-width="500">
<p lang="en" dir="ltr">I implemented GRPO and DPO from scratch in vanilla Pytorch to unravel every piece of training details. Hope it could be helpful for those who care about the implementation details of the algorithms. ðŸ‘‰ <a href="https://t.co/1Exq7GTkLY" rel="external nofollow noopener" target="_blank">https://t.co/1Exq7GTkLY</a> <a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">#AI</a> <a href="https://twitter.com/hashtag/RL?src=hash&amp;ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">#RL</a> <a href="https://twitter.com/hashtag/LLM?src=hash&amp;ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">#LLM</a></p>â€” Ming Yin (@MingYin_0312) <a href="https://twitter.com/MingYin_0312/status/1955351703626154017?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">August 12, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<!-- 

****

****
 -->

<!-- ## Miscellaneous

My nice collaborator also shared this on twitter: 
<div class='jekyll-twitter-plugin'><blockquote class="twitter-tweet" data-width="500"><p lang="en" dir="ltr">New preprint on offline RL:<a href="https://t.co/2vv2KLA1TF">https://t.co/2vv2KLA1TF</a><br><br>* A variance reduction algorithm for offline RL<br>* Optimal horizon dependence: O(H^2/d_m) sample complexity on time-homogeneous MDPs<br><br>Joint w/ Ming Yin (<a href="https://twitter.com/MingYin_0312?ref_src=twsrc%5Etfw">@MingYin_0312</a>) and Yu-Xiang Wang</p>&mdash; Yu Bai (@yubai01) <a href="https://twitter.com/yubai01/status/1358887058274570241?ref_src=twsrc%5Etfw">February 8, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div> -->

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/dpo.bib"></d-bibliography>
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2025 Ming  Yin. 
      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9NJFB4PFB4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-9NJFB4PFB4');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
